---
layout: post
title: ELK (elasticsearch, logstash, kibana) 日志分析平台搭建
category: 技术
tags: ELK
keywords:
description:
---


ELK是啥, 其实是是三个组件的缩写, 分别是elasticsearch, logstash, kibana. ELK平台可以用于实现日志收集、日志搜索和日志分析.
当然, 如果你有花不完的money, 完全可以使用商业版的Splunk, Orz...

###1. ELK分别是什么
1). ELK现在都是属于elastic公司的产品, <a href="https://www.elastic.co/products"  target="_blank">产品主页</a>.

> 1.elasticsearch(es): 它是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。<br>
> 2.logstash: 简单说是一个日志收集工具, 可以定义从哪里获取数据, 并且可以简单处理数据, 最后可以定义将数据输出到哪里, 一般输出到es. <br>
> 3.kibana: 其实就是一个数据展示界面, 并且可以分析数据, 例如从es中读取数据进行展示分析. es自己也带有简单的展示dashboard: http://127.0.0.1:9200/_plugin/head/, 当然
前提是你安装了head插件, 这个下面再说.

2). 简单流程

下面图简单的展示了三组件之间的协作,

![1](/public/img/grocery/elk/elk-1.jpg  "elk flow graph")<br>

总的来说分成四大部分, 第一, 应用产生数据, 第二, logstash从应用收集数据, 第三, 将数据放入es, 第四, 使用kibana进行数据展示以及分析.


###2. 简单平台搭建
我使用的系统是mac os, 其他Linux平台(windows算了)下的安装步骤大致是一样的, 只是安装一些包使用apt-get或者yum, mac中使用的是brew, 同时安装后的软件的路径肯定是不太一样的.

> 安装命令使用: brew install XXX
>
> 1.Elasticserach版本: 2.4.0 <br>
> 2.logstash版本: 2.4.0, 注意: Logstash 1.5以上版本不低于java 1.7，因此推荐使用最新版本的Java. <br>
> 3.kibana版本: 4.5.1, k4要求ES的版本不能太低, 所以尽量安装最新版本. <br>

1). 安装完ES之后, 直接启动es(使用elasticsearch就ok, 如果是使用brew安装, 那么环境变量已经包含在PATH中了), 那么在localhost:9200能看到:

```
{
  "name" : "Stephen Colbert",
  "cluster_name" : "whoami_es",
  "version" : {
    "number" : "2.4.0",
    "build_hash" : "ce9f0c7394dee074091dd1bc4e9469251181fc55",
    "build_timestamp" : "2016-08-29T09:14:17Z",
    "build_snapshot" : false,
    "lucene_version" : "5.5.2"
  },
  "tagline" : "You Know, for Search"
}
```

说明安装成功了. es的配置, 目前使用default的配置就OK了.

之前有说过, es也有简单的展示数据的dashboard, 但是需要下载一个head插件, 那么你需要进到安装路径下进行(mac应该是/usr/local/Cellar/elasticsearch/2.4.0/libexec),
执行'''./bin/plugin install mobz/elasticsearch-head''', 安装完之后, 如果你的es有数据, 那么就可以在http://127.0.0.1:9200/_plugin/head/看到数据.

![2](/public/img/grocery/elk/elk-2.jpg  "es head")<br>

想要具体了解界面的元素意义, 参考一篇blog: <a href="http://blog.csdn.net/laigood/article/details/8193758"  target="_blank">分布式搜索elasticsearch集群管理工具head</a>.


2). logstash的功能之前已经说了, 本质上说就是收集数据. 我们需要为它指定input, output和filter（注意input和output可以是多个）. 基本流程如下:

![3](/public/img/grocery/elk/elk-3.jpg  "logstash 3")<br>

简单的启动logstash, 可以使用命令```logstash -e ''```, logstash的默认输入是标准输入(stdin), 默认输出是标准输出(stdout). 现在我们可以在终端随便
输入一些字符串例如"qqq", 那么输出是什么呢? 看下图:

![4](/public/img/grocery/elk/elk-4.jpg  "logstash 4")<br>

logstash会自动加上一些特殊字段: timestamp,version,type等. (一些细节目前不讲太多~)

当然我们可以自己写自己的配置文件, 首先创建一个文件, 命名为"logstash.conf", 随便写点配置:

```
input {
    stdin{}
}

output {
    stdout{}
}

// 此处暂时不说fliter字段, 目前需要不到
```

然后使用```logstash -f XXX/XXX/logstash.conf```, 在启动的时候加载这个conf文件, 效果和之前是一样的.

下面简单说说使用redis作为broker的简单实例, 看下图:

![5](/public/img/grocery/elk/elk-5.jpg  "logstash 5")<br>

这个例子的目的仅仅在于, 将redis作为logstash的broker的简单模拟, 第二个logstash并没有执行实际的ES的建立索引过程, 仅仅是输出数据到stdout.

基本流程: logstash1从stdin(应用程序)读取数据, 将数据缓存在消息队列redis中, logstash2从消息队列redis中读取数据并进行处理, 最终输出到stdout(例如ES)中.
此处的redis作为简单的消息队列, 所以使用kafka使用OK的.

我们需要开启两个logstash进程, 第一个的配置是:

```
input { stdin {} }

output {
    redis {
        data_type => "channel"
        key => "logstash-chan-%{+yyyy.MM.dd}"
    }
}

// 输入到redis, 对应的key是logstash-chan-%{+yyyy.MM.dd}
```

第二个配置是:

```
input {
    redis {
        data_type => "pattern_channel"
        key => "logstash-*"
        host => "192.168.0.105"
        port => 6379
        threads => 5
    }
}

// 接收redis中key是"logstash-*"的数据, 注意改成自己的host

output {
    stdout {
        codec => "json_lines"
    }
}
// 输出到stdout
```

分别在两个终端启动两个logstash, 注意: 需要首先启动redis-server, 然后在redis-cli中使用```PUBLISH logstash-test "xxx000" ```,
那么会在第二个logstash中显示输出...

最后, 如果想要输出到es, 那么可以做下面配置:

```
input {
    stdin{}
}

output {
  elasticsearch {
    action => "index"            # 在ES上操作index
    hosts  => "localhost:9200"   # ES地址
    index  => "test"             # 索引名
  }
```

启动ES和logstash后, 在终端输出111,222,333,444,555这个5个数据, 那么现在看看http://127.0.0.1:9200/_plugin/head/看到什么.

![6](/public/img/grocery/elk/elk-6.jpg  "logstash 6")<br>

可以看到, 多了一个test索引, 并且看到文档的数量是5个...赞~ 这样其实是完成了logstash到ES的输出定向.


3).kibana从ES读取数据并且展示&分析. 我们需要在kibana的配置文件中配置ES的地址信息等. 我安装的是K4, 配置文件是在目录kibana/4.5.1/config下,
修改kibana.yml文件(K3下是kibana.conf文件), 加上ES信息,

```
# Kibana is served by a back end server. This controls which port to use.
 server.port: 5601

# The host to bind the server to.
 server.host: "127.0.0.1"

# The Elasticsearch instance to use for all your queries.
 elasticsearch.url: "http://127.0.0.1:9200"

# 最重要的就是上面几个, 其他的自己看着办...
```

现在启动kibana, 打开网页http://127.0.0.1:5601, 理论上说能看到下面界面:

![7](/public/img/grocery/elk/elk-7.jpg  "kibana 7")<br>

注意: 如果你不能看到内容或者上面的菜单栏, 说明ES版本太低了, 需要安装高版本.

> 配置ES的索引显示

首先需要加上我们刚刚建立的索引test, 点击setting->indices, 在这里我们可以Configure an index pattern, 也就是说可以配置
正则匹配的index, 可以看到默认的index是"logstash-*", 默认是从logstash导出的数据, 我们可以改成test. 下面还有一个Time-field name,
一般来说time都是一个必要的字段, 并且这个字段的类型是date类型! 不是string!!! 如果没有时间字段, 那么将上面的" Index contains time-based events"
取消就OK.

![8](/public/img/grocery/elk/elk-8.png  "kibana 8")<br>

OK, 现在创建后, 能够看到下图:

![9](/public/img/grocery/elk/elk-9.jpg  "kibana 9")<br>

哇塞, 可以看到我们在es中的test字段了, message就是之前输入的数据111,222,333,444,555的字段名, 下面来看看实际的数据是啥样的.

点击菜单栏: Discover, 如果没有看到数据, 那么点击右边的时间, 改成Today, 现在你应该能看到数据了吧...反正我能看到:

![10](/public/img/grocery/elk/elk-10.png  "kibana 10")<br>

我们可以看到之前的输入的数据111,222,333,444,555,啊哈~ 最上面的搜索框还能支持搜索哦~~~

还可以将数据进行一些图形化操作, 点击菜单栏: visualize, 例如做一个简单的柱状图, 点击"Vertical bar chart", --> "From a new search",
那么我们进入到图形初始化界面:

![11](/public/img/grocery/elk/elk-11.jpg  "kibana 11")<br>

左边有很多参数可选, 慢慢玩去~~~

最后, 还可以将图形保存, 看上面图形, 点击右上角的"保存"按钮, 可以进行保存, 下次需要看的时候, 点击Dashboard, 然后点击click+就可以加载我们保存的图形, 赞~

![12](/public/img/grocery/elk/elk-12.jpg  "kibana 12")<br>

OK, ELK简单搭建到此为止, 具体的细节, 以后再慢慢看吧...